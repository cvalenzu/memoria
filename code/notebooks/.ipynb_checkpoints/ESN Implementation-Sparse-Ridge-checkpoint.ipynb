{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.cmap'] = 'jet'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# files = [\"informe_Lagunillas_20170728235145.xls\",  \"informe_Lota_Urbana_20170729002437.xls\",\n",
    "# \"informe_Lota_Rural_20170728235710.xls\",  \"informe_Meteorologia_20170729002107.xls\"]\n",
    "# names = [\"lagunillas\", \"lota_u\", \"lota_r\", \"meteo\"]\n",
    "\n",
    "# for file,name in zip(files,names):\n",
    "#     data = pd.read_html(\"../data/\"+file,header=0)[0]\n",
    "#     d = data[\"Velocidad Viento\"]\n",
    "#     datetime = pd.to_datetime(data[\"Fecha\"] + \" \" + data[\"Hora\"],format=\"%d-%m-%Y %H:%M\")\n",
    "#     d.index = datetime\n",
    "#     d.to_csv(\"../data/\"+name+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def getDataWindowed(data,inSize,outSize):\n",
    "    biggest = np.max([inSize,outSize])\n",
    "    \n",
    "    matrixIn = np.zeros((len(data)-2*biggest, inSize))\n",
    "    matrixOut = np.zeros((len(data)-2*biggest, outSize))\n",
    "    for i in range(len(data)-2*biggest):\n",
    "        matrixIn[i,:] = data[i:i+inSize]\n",
    "        matrixOut[i,:] = data[i+inSize+1:i+inSize+outSize+1]\n",
    "    return matrixIn,matrixOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createFolds(dataSize, k):\n",
    "    vector = np.arange(dataSize)\n",
    "    splitted = np.array_split(vector,k+1)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    test_set = []\n",
    "    for i in range(k):\n",
    "        test_set = np.hstack((test_set, splitted[i]))\n",
    "        val_set = splitted[i+1]\n",
    "        folds.append((test_set.astype('int'),val_set.astype('int')))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/meteo.csv\",index_col=0,names=[\"datetime\",\"windspeed\"])[\"windspeed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = getDataWindowed(data, 12,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ESN(BaseEstimator,RegressorMixin):\n",
    "    def __init__(self, n_reservoir = 1000, spectral_radius = 0.135, sparsity=0,\n",
    "                 leaking_rate=0.3, regularization=1, random_state = None, activation = np.tanh):\n",
    "        self.n_inputs = None\n",
    "        self.n_outputs = None\n",
    "        self.n_reservoir = n_reservoir\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.sparsity = sparsity\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.regularization = regularization\n",
    "        self.last_state = None\n",
    "        self.activation = activation\n",
    "        if random_state:\n",
    "            if type(random_state) is int:\n",
    "                self.random_state=np.random.RandomState(random_state)\n",
    "            elif type(random_state) is np.random.RandomState:\n",
    "                self.random_state = random_state\n",
    "        else:\n",
    "            self.random_state = np.random.RandomState()\n",
    "    \n",
    "        #Creating Reservoir weights\n",
    "        self.W = self.random_state.rand(self.n_reservoir,self.n_reservoir)-0.5\n",
    "        #Sparsity\n",
    "        self.W[self.random_state.rand(*self.W.shape) < self.sparsity] = 0\n",
    "        self.W = sp.csr_matrix(self.W)\n",
    "        #Spectral radius\n",
    "        self.W *= self.spectral_radius\n",
    "\n",
    "    def get_params(self,deep=True):\n",
    "        params =  {'n_reservoir':self.n_reservoir,'spectral_radius':self.spectral_radius,  'sparsity':self.sparsity,\n",
    "                  'leaking_rate': self.leaking_rate, \"regularization\":self.regularization, \"activation\": self.activation}\n",
    "        if self.n_inputs and self.n_outputs:\n",
    "            params[\"n_inputs\"] = self.n_inputs\n",
    "            params[\"n_outputs\"] = self.n_outputs\n",
    "        if self.random_state:\n",
    "            params[\"random_state\"] = self.random_state\n",
    "        return params\n",
    "\n",
    "    @jit\n",
    "    def fit(self,X,y):\n",
    "        in_rows,self.n_inputs = X.shape\n",
    "        if len(y.shape) > 1:\n",
    "            out_rows, self.n_outputs = y.shape\n",
    "        else:\n",
    "            out_rows = len(y)\n",
    "            self.n_outputs = 1\n",
    "        initLen = int(0.01*in_rows)\n",
    "\n",
    "        #Raise exception\n",
    "        assert(in_rows == out_rows)\n",
    "\n",
    "        #Input length\n",
    "        N = in_rows\n",
    "\n",
    "        #Creating input weights\n",
    "        self.Win = (self.random_state.rand(self.n_reservoir,1+self.n_inputs)-0.5) * 1\n",
    "\n",
    "        #Creating state matrix\n",
    "        X_states = np.zeros((1+self.n_inputs+self.n_reservoir,N-initLen))\n",
    "\n",
    "        #Last state\n",
    "        self.last_state  = np.zeros(self.n_reservoir)\n",
    "\n",
    "        #Collecting states\n",
    "        for t in range(N):\n",
    "            u = X[t]\n",
    "            #Calculating new state\n",
    "            self.last_state = (1-self.leaking_rate)*self.last_state  + self.leaking_rate*self.activation( np.dot( self.Win, np.hstack((1,u)) ) \\\n",
    "                                                                    + self.W.dot(self.last_state) )\n",
    "            if t >= initLen:\n",
    "                X_states[:,t-initLen] = np.hstack((1,u,self.last_state ))\n",
    "\n",
    "\n",
    "        Y_T = y[initLen:].T\n",
    "\n",
    "        X_sqrd = np.dot(X_states,X_states.T)+  self.regularization*np.eye(1+self.n_inputs+self.n_reservoir)\n",
    "        Y_sqrd = np.dot(Y_T,X_states.T)\n",
    "\n",
    "        #Getting the output weights using least squares\n",
    "        self.Wout=np.dot(Y_sqrd, np.linalg.inv(X_sqrd))\n",
    "\n",
    "        return self\n",
    "\n",
    "    @jit\n",
    "    def predict(self,X, cont=False):\n",
    "        Y = np.empty((len(X),self.n_outputs))\n",
    "        if not cont:\n",
    "            last_state = np.zeros_like(self.last_state)\n",
    "        else:\n",
    "            last_state = self.last_state\n",
    "            \n",
    "        for t,u in enumerate(X):\n",
    "                last_state = (1 - self.leaking_rate) * last_state + self.leaking_rate*self.activation( np.dot( self.Win, np.hstack((1,u)))+ \\\n",
    "                                                                     + self.W.dot( last_state  ) )\n",
    "                y = np.dot(self.Wout, np.hstack((1,u,last_state)))\n",
    "                Y[t,:] = y\n",
    "\n",
    "        if cont:\n",
    "            self.last_state = last_state\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate the ESN reservoir\n",
    "inSize = 12\n",
    "outSize = 12\n",
    "resSize = 1000\n",
    "a = 0.3 # leaking rate\n",
    "\n",
    "# load the data\n",
    "trainLen = 2000\n",
    "testLen = 2000\n",
    "initLen = 100\n",
    "\n",
    "data = np.loadtxt('MackeyGlass_t17.txt')\n",
    "X, y= getDataWindowed(data,inSize,outSize)\n",
    "X_train, y_train = (X[:trainLen], y[:trainLen])\n",
    "X_test, y_test = (X[trainLen:trainLen+testLen], y[trainLen:trainLen+testLen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1000000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esn = ESN(random_state=42, n_reservoir=resSize, leaking_rate=a)\n",
    "esn.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 3.38 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit esn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_approx= esn.predict(X_test,cont=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 12)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_approx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11870135593e-05\n",
      "0.99975951983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tronco/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py:482: DeprecationWarning: Default 'multioutput' behavior now corresponds to 'variance_weighted' value which is deprecated since 0.17, it will be changed to 'uniform_average' starting from 0.19.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "print(mean_squared_error(y_test,y_approx))\n",
    "print(r2_score(y_test,y_approx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
